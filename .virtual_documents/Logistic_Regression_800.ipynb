import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd
import plotly.express as px
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


#to download data
import gdown
dataset_url = "https://drive.google.com/u/1/uc?id=1X7-HGxDHR54J60vdrwekaML-blIHQjBi&export=download"
filename = "train.csv"
gdown.download(dataset_url, filename)



df = pd.read_csv('train.csv')


df.head()











df.dtypes


df.info()


df.isna().sum()





df.isna().sum()/len(df) * 100






sns.heatmap(df.isna().transpose())


df.describe()


df.describe(include='object')





df.columns


df.head(2)


sns.countplot(x='Survived', data = df) # barplot of Survived column



fig = px.pie(df, names = 'Survived')
fig.update_layout(width = 700, height = 400)
fig.show()








sns.countplot(data = df, x='Pclass', hue = 'Survived')








df.head(2)


sns.countplot(data = df, x='Sex', hue = 'Survived')





df.head(2)





sns.boxplot(data=df, x='Pclass', y = 'Age')


df.groupby('Pclass').Age.median()








# df[['Pclass', 'Age']]


def fill_age(col):
    pclass = col[0]
    age = col[1]
    if pd.isna(age):
        if pclass == 1:
            return 37
        elif pclass == 2:
            return 29
        else:
            return 24
    return age


df.Age = df[['Pclass', 'Age']].apply(fill_age, axis = 'columns')


df.isna().sum()





df.drop(columns=['Cabin'], inplace = True)





df.dropna(inplace = True)


df.isna().sum()


df.head(2)





df.drop(columns = ['PassengerId', 'Name', 'Ticket'], inplace = True)


df.head()





X = df.iloc[:, 1:] # independent
y = df.Survived # dependent


X.head()





X_encoded = pd.get_dummies(columns = ['Sex', 'Embarked'], drop_first = True, data = X)
X_encoded.head(2)






X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2, random_state = 42) # 80% training and 20% testing data








from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=5000)
model.fit(X_train, y_train)
model.score(X_test, y_test) # accuracy


from sklearn.metrics import (accuracy_score,
                             recall_score,
                             precision_score,
                             f1_score,
                             confusion_matrix,
                             ConfusionMatrixDisplay,
                             classification_report)


y_pred = model.predict(X_test)
accuracy  = accuracy_score(y_true = y_test, y_pred=y_pred)
precision  = precision_score(y_true = y_test, y_pred=y_pred)
recall  = recall_score(y_true = y_test, y_pred=y_pred)
f1 = f1_score(y_true = y_test, y_pred=y_pred)
confusion_matrix = confusion_matrix(y_true = y_test, y_pred=y_pred)
report = classification_report(y_true = y_test, y_pred=y_pred)


print("accuracy: ", accuracy)
print("precision: ", precision)
print("recall: ", recall)
print("f1-score: ", f1)
print("\nConfusion Matrix : \n", confusion_matrix)
print("\n\n Classification Report : \n", report)


y_test.value_counts()


ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='BuGn')





from sklearn.ensemble import RandomForestClassifier


# Train Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)


# Predictions
y_pred_rf = rf.predict(X_test)


# Evaluate Model
print("Random Forest Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred_rf):.4f}")


from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Compute confusion matrix
cm_rf = confusion_matrix(y_test, y_pred_rf)

# Plot confusion matrix
plt.figure(figsize=(5, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest')
plt.show()








import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Input


# Build Neural Network Model

model_nn = Sequential([
    Input(shape=(8,)), 
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid') # binary classification
])


# Compile Model
model_nn.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])


print(X_train.shape)  # (num_samples, num_features)
print(X_test.shape)


# Train Model
history = model_nn.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))


plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()



# Evaluate Model
y_pred_nn = (model.predict(X_test) > 0.5).astype("int32").flatten()

print("Neural Network Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nn):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_nn):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_nn):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred_nn):.4f}")






# Generate predictions
y_pred_log = model.predict(X_test)  # Logistic Regression
y_pred_rf = rf.predict(X_test)    # Random Forest
y_pred_nn = model_nn.predict(X_test)    # Neural Network


# Convert Neural Network outputs to class labels 
if y_pred_nn.shape[-1] > 1:  
    y_pred_nn = y_pred_nn.argmax(axis=1)  # For multi-class classification
else:
    y_pred_nn = (y_pred_nn > 0.5).astype(int)  # For binary classification


# Create DataFrame to compare models
model_performance = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest', 'Neural Network'],
    'Accuracy': [
        accuracy_score(y_test, y_pred_log),
        accuracy_score(y_test, y_pred_rf),
        accuracy_score(y_test, y_pred_nn)
    ],
    'Precision': [
        precision_score(y_test, y_pred_log, average='weighted'),
        precision_score(y_test, y_pred_rf, average='weighted'),
        precision_score(y_test, y_pred_nn, average='weighted')
    ],
    'Recall': [
        recall_score(y_test, y_pred_log, average='weighted'),
        recall_score(y_test, y_pred_rf, average='weighted'),
        recall_score(y_test, y_pred_nn, average='weighted')
    ],
    'F1 Score': [
        f1_score(y_test, y_pred_log, average='weighted'),
        f1_score(y_test, y_pred_rf, average='weighted'),
        f1_score(y_test, y_pred_nn, average='weighted')
    ]
})

print(model_performance)










